#!/bin/sh
set -eux

architecture="$(uname -m)"
if [ "${architecture}" != "x86_64" ] && [ "${architecture}" != "s390x" ]; then
  echo "Skipping test as CPU hotplugging not supported on ${architecture}"
fi

# Install LXD
install_lxd

# required for "CPU auto pinning" feature check
# as we don't have a separate API extension for it
# and we rely on the debug output in the LXD daemon logs.
snap set lxd daemon.debug=true
systemctl restart snap.lxd.daemon.service

# Configure LXD
lxc network create lxdbr0
lxc profile device add default eth0 nic network=lxdbr0

IMAGE="${TEST_IMG:-ubuntu-minimal-daily:24.04}"

poolName="vmpool$$"
poolDriver=dir

echo "==> Create storage pool using driver ${poolDriver}"
lxc storage create "${poolName}" "${poolDriver}"

# limits.kernel.* aren't valid for VMs, but profiles with the key set should
# still work
lxc profile set default limits.kernel.nofile 50

! lxc init v0 --vm --empty -c limits.kernel.cpu=46 -s "${poolName}" || false

lxc init v0 --vm --empty -s "${poolName}"

# limits.kernel.* only applies to containers (shouldn't work)
! lxc config set v0 limits.kernel.as=1GiB || false

lxc delete v0

echo "==> Create ephemeral VM and boot"
lxc launch "${IMAGE}" v1 --vm -s "${poolName}" --ephemeral
waitInstanceReady v1
lxc info v1

# Get number of CPUs
# shellcheck disable=SC2010
cpuCount="$(ls /sys/devices/system/cpu | grep -xEc 'cpu[[:digit:]]+')"

# VMs should have only 1 CPU per default
[ "$(lxc exec v1 -- ls /sys/devices/system/cpu | grep -xEc 'cpu[[:digit:]]+')" -eq "1" ]

# Set valid CPU limits (low to high)
for i in $(seq 2 "${cpuCount}"); do
  lxc config set v1 limits.cpu="${i}"
  [ "$(lxc exec v1 -- ls /sys/devices/system/cpu | grep -xEc 'cpu[[:digit:]]+')" -eq "${i}" ]
done

# Try setting more CPUs than available
! lxc config set v1 limits.cpu="$(( cpuCount + 1 ))" || false

# Set valid CPU limits (high to low)
for i in $(seq "${cpuCount}" -1 1); do
  lxc config set v1 limits.cpu="${i}"
  [ "$(lxc exec v1 -- ls /sys/devices/system/cpu | grep -xEc 'cpu[[:digit:]]+')" -eq "${i}" ]
done

# Try doing pinning while VM is running (shouldn't work)
! lxc config set v1 limits.cpu=1,2 || false

# Set max CPU count
lxc config set v1 limits.cpu="${cpuCount}"
[ "$(lxc exec v1 -- ls /sys/devices/system/cpu | grep -xEc 'cpu[[:digit:]]+')" -eq "${cpuCount}" ]

# check that CPU affinity is automatically set if feature present
QEMU_PID=$(lxc info v1 | awk '/^PID:/ {print $2}')
if journalctl --quiet --no-hostname --no-pager --boot=0 --unit=snap.lxd.daemon.service | grep "Scheduler: virtual-machine"; then
  # Check that there are processes with pinning set
  # It will be shown like this (for limits.cpu=2):
  # pid 2894's current affinity list: 6
  # pid 2895's current affinity list: 8
  # pid 2897's current affinity list: 0-15
  # pid 2898's current affinity list: 0-15
  # pid 2899's current affinity list: 0-15
  # 2894 and 2895 have affinity set, while others don't
  PINNED_THREADS_NUM=$(taskset --cpu-list -a -p "${QEMU_PID}" | grep -cE ':\s+[0-9]+$')
  [ "${PINNED_THREADS_NUM}" -ge "$(lxc config get v1 limits.cpu)" ]
else
  # check that there is no pinning set
  ! taskset --cpu-list -a -p "${QEMU_PID}" | grep -E ':\s+[0-9]+$' || false
  taskset --cpu-list -a -p "${QEMU_PID}" | grep "0-$((cpuCount-1))"
fi

# Unset CPU limit
lxc config unset v1 limits.cpu

# Unsetting the limit should leave the VM with 1 CPU
[ "$(lxc exec v1 -- ls /sys/devices/system/cpu | grep -xEc 'cpu[[:digit:]]+')" -eq "1" ]

echo "==> Stopping and deleting ephemeral VM"
# Stop VM and check its deleted.
lxc stop -f v1
! lxc info v1 || false

lxc profile device remove default eth0
lxc profile unset default limits.kernel.nofile

echo "==> Deleting storage pool"
lxc storage delete "${poolName}"

echo "==> Deleting storage pool"
lxc network delete lxdbr0

# shellcheck disable=SC2034
FAIL=0
